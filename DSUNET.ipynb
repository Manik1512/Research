{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "df1ccbb2-fa1e-4f1c-b007-08aa920ad97a",
      "metadata": {
        "id": "df1ccbb2-fa1e-4f1c-b007-08aa920ad97a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-08 19:38:11.418101: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-02-08 19:38:11.429083: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739023691.441368   12348 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739023691.444842   12348 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-08 19:38:11.456776: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input,Conv2D,BatchNormalization,Concatenate,Conv2DTranspose,MaxPooling2D,Activation,Layer,UpSampling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "regmSJRZ2cUt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "regmSJRZ2cUt",
        "outputId": "20f17887-0806-4dd8-bc18-81df81efac95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.18.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /home/manik/tf-gpu/lib/python3.10/site-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: focal-loss\n"
          ]
        }
      ],
      "source": [
        "!pip show tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c69976-0016-4214-8060-187e4391c01c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "20c69976-0016-4214-8060-187e4391c01c",
        "outputId": "848d1554-4373-457a-d833-3c079b5ded85"
      },
      "outputs": [],
      "source": [
        "from focal_loss import BinaryFocalLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06922290-6b99-4520-8dd7-3e1a9c2527ec",
      "metadata": {
        "id": "06922290-6b99-4520-8dd7-3e1a9c2527ec"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "24a405f3-485d-452e-a9c2-61e9bd9b3424",
      "metadata": {
        "id": "24a405f3-485d-452e-a9c2-61e9bd9b3424"
      },
      "outputs": [],
      "source": [
        "\n",
        "class InPlaceABN(Layer):\n",
        "    def __init__(self, activation='relu', momentum=0.99, epsilon=1e-3, **kwargs):\n",
        "\n",
        "        super(InPlaceABN, self).__init__(**kwargs)\n",
        "        self.momentum = momentum\n",
        "        self.epsilon = epsilon\n",
        "        self.activation = activation\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create trainable parameters for batch normalization\n",
        "        self.gamma = self.add_weight(\n",
        "            name='gamma', shape=(input_shape[-1],), initializer='ones', trainable=True\n",
        "        )\n",
        "        self.beta = self.add_weight(\n",
        "            name='beta', shape=(input_shape[-1],), initializer='zeros', trainable=True\n",
        "        )\n",
        "        self.moving_mean = self.add_weight(\n",
        "            name='moving_mean', shape=(input_shape[-1],), initializer='zeros', trainable=False\n",
        "        )\n",
        "        self.moving_variance = self.add_weight(\n",
        "            name='moving_variance', shape=(input_shape[-1],), initializer='ones', trainable=False\n",
        "        )\n",
        "        super(InPlaceABN, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # Compute batch statistics if in training mode\n",
        "        if training:\n",
        "            batch_mean, batch_var = tf.nn.moments(inputs, axes=[0, 1, 2], keepdims=False)\n",
        "            # Update moving averages\n",
        "            self.moving_mean.assign(self.moving_mean * self.momentum + batch_mean * (1 - self.momentum))\n",
        "            self.moving_variance.assign(self.moving_variance * self.momentum + batch_var * (1 - self.momentum))\n",
        "        else:\n",
        "            # Use moving averages during inference\n",
        "            batch_mean = self.moving_mean\n",
        "            batch_var = self.moving_variance\n",
        "\n",
        "        # Apply Batch Normalization\n",
        "        normalized_inputs = (inputs - batch_mean) / tf.sqrt(batch_var + self.epsilon)\n",
        "        bn_output = self.gamma * normalized_inputs + self.beta\n",
        "\n",
        "\n",
        "        return tf.nn.relu(bn_output)\n",
        "\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3e8a1e38-37e3-4603-b66f-1714bf74ec2f",
      "metadata": {
        "id": "3e8a1e38-37e3-4603-b66f-1714bf74ec2f"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "def dice_loss(y_true, y_pred, epsilon=1e-7):\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
        "\n",
        "    denominator = tf.reduce_sum(y_true + y_pred, axis=[1, 2, 3]) + epsilon\n",
        "\n",
        "    dice_coefficient = numerator / denominator\n",
        "    loss = 1 - dice_coefficient\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "fl=BinaryFocalLoss(gamma=3)\n",
        "\n",
        "def fused_loss(y_true, y_pred, kappa=1.0):\n",
        "    dice = dice_loss(y_true, y_pred)\n",
        "    focal = fl(y_true, y_pred)\n",
        "    total_loss = dice + kappa * focal\n",
        "    return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd3b7950-8b97-45e6-abaf-8ab1ed36e075",
      "metadata": {
        "id": "bd3b7950-8b97-45e6-abaf-8ab1ed36e075"
      },
      "outputs": [],
      "source": [
        "# def decoder_block(input,skip_features,num_filters):\n",
        "#     x=Conv2DTranspose(num_filters,(2,2),strides=2,padding=\"same\")(input)\n",
        "#     x=Concatenate()([x,skip_features])   #jin do feature map ko combine kerna hai\n",
        "#     x=conv_block(x,num_filters)\n",
        "#     return x\n",
        "\n",
        "# def conv_block(input,skip_features,num_filters):\n",
        "#     x=Concatenate()([x,skip_features])\n",
        "#     x=Conv2D(num_filters,3,padding=\"same\")(input)\n",
        "#     x=BatchNormalization()(x)\n",
        "#     x=Activation(\"relu\")(x)\n",
        "\n",
        "#     x=Conv2D(num_filters,3,padding=\"same\")(x)\n",
        "#     x=BatchNormalization()(x)\n",
        "#     x=Activation(\"relu\")(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09991a27-62c7-471e-a118-e563e0e211d4",
      "metadata": {
        "id": "09991a27-62c7-471e-a118-e563e0e211d4"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Model\n",
        "\n",
        "# def encoder(input_shape):\n",
        "#     # Create the DenseNet121 model\n",
        "#     base_model = tf.keras.applications.DenseNet121(weights=None, include_top=False, input_shape=input_shape)\n",
        "#     base_model.trainable = True  # Allow training\n",
        "\n",
        "#     # Define new inputs\n",
        "#     inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "#     # Pass inputs through the base DenseNet model\n",
        "#     x = base_model(inputs)\n",
        "\n",
        "#     # Extract intermediate outputs using the same computation graph\n",
        "#     s1 = base_model.get_layer('conv1/relu').output  # First block output\n",
        "#     dense_block1 = base_model.get_layer('pool2_relu').output  # First dense block\n",
        "#     dense_block2 = base_model.get_layer('pool3_relu').output  # Second dense block\n",
        "#     dense_block3 = base_model.get_layer('pool4_relu').output  # Third dense block\n",
        "#     transition_block3 = base_model.get_layer('conv5_block1_0_relu').output  # Transition block output\n",
        "\n",
        "#     # Return a functional model\n",
        "#     return Model(inputs=inputs, outputs=[s1, dense_block1, dense_block2, dense_block3, transition_block3])\n",
        "\n",
        "# # Initialize the encoder\n",
        "# encoder_part = encoder((256, 256, 3))\n",
        "# encoder_part.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "21708a44-2a2d-4299-9195-9425fad197de",
      "metadata": {
        "id": "21708a44-2a2d-4299-9195-9425fad197de"
      },
      "outputs": [],
      "source": [
        "def encoder(input_shape):\n",
        "    encoder_model = tf.keras.applications.DenseNet121(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
        "    encoder_model.trainable =False\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    ouput= encoder_model(inputs)\n",
        "\n",
        "    s1=encoder_model.get_layer('conv1_relu').output   #output for 4th conct operation\n",
        "    s2=encoder_model.get_layer('pool1').output        #output for 3rd conct operation\n",
        "    s3=encoder_model.get_layer('pool2_pool').output   #output for 2nd conct operation\n",
        "    s4=encoder_model.get_layer('pool3_pool').output   #output for 1st conct operation\n",
        "    s5=encoder_model.get_layer('pool4_pool').output   #ouput of encoder\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print(s5.shape)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=[s1,s2,s3,s4,s5],name=\"encoder\")\n",
        "    #return Model(inputs=inputs, outputs=transition_block3)\n",
        "\n",
        "#pool2_relu->1st dense block end  (None, 128, 128, 256)\n",
        "#pool3_relu  (None, 64, 64, 512)\n",
        "#poo4_relu  (32,32,1024)\n",
        "#relu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ltexudSMUqV_",
      "metadata": {
        "id": "ltexudSMUqV_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b272dd96-abec-44a6-90fd-036f4ad41ad7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b272dd96-abec-44a6-90fd-036f4ad41ad7",
        "outputId": "6cc14f53-fc0c-4ce8-e190-d0636ff33510"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "(None, 128, 128, 64)\n",
            "(None, 64, 64, 64)\n",
            "(None, 32, 32, 128)\n",
            "(None, 16, 16, 256)\n",
            "(None, 8, 8, 512)\n"
          ]
        }
      ],
      "source": [
        "encoder_part=encoder((256,256,3))\n",
        "s1,s2,s3,s4,s5=encoder_part.outputs   #num_filters_list=[256,512,256,64,32]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3pwtqBRJ75oe",
      "metadata": {
        "id": "3pwtqBRJ75oe"
      },
      "outputs": [],
      "source": [
        "# encoder_part.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7c0e7c73-ea61-4119-8e01-4109b898471d",
      "metadata": {
        "id": "7c0e7c73-ea61-4119-8e01-4109b898471d"
      },
      "outputs": [],
      "source": [
        "\n",
        "def conv_block(input,num_filters):# yellow part in decoder\n",
        "\n",
        "    x=Conv2D(num_filters,3,padding=\"same\")(input)\n",
        "    x=InPlaceABN(activation='relu')(x)\n",
        "    x=Conv2D(num_filters,3,padding=\"same\")(x)\n",
        "    x=InPlaceABN(activation='relu')(x)\n",
        "    return x\n",
        "\n",
        "def decoder_block(input,skip_features,num_filters):# blue part in decoder\n",
        "\n",
        "    x=Conv2DTranspose(num_filters,(2,2),strides=2,padding=\"same\")(input)\n",
        "    print(x.shape)\n",
        "    x=Concatenate()([x,skip_features])\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = InPlaceABN(activation='relu')(x)\n",
        "    return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "63151232-9941-4264-a075-2ce9314d5ef5",
      "metadata": {
        "id": "63151232-9941-4264-a075-2ce9314d5ef5"
      },
      "outputs": [],
      "source": [
        "def decoder(input_shape, skip_connections, num_filters_list):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    s1,s2,s3,s4,s5=skip_connections\n",
        "\n",
        "    x=decoder_block(x,s4,num_filters_list[0])\n",
        "    x=conv_block(x,num_filters_list[0])\n",
        "\n",
        "    x=decoder_block(x,s3,num_filters_list[1])\n",
        "    x=conv_block(x,num_filters_list[1])\n",
        "\n",
        "    x=decoder_block(x,s2,num_filters_list[2])\n",
        "    x=conv_block(x,num_filters_list[2])\n",
        "\n",
        "    x=decoder_block(x,s1,num_filters_list[3])\n",
        "    x=conv_block(x,num_filters_list[3])\n",
        "\n",
        "    # x=decoder_block(x,s1,num_filters_list[4])\n",
        "    # x=conv_block(x,num_filters_list[4])\n",
        "\n",
        "    x = Conv2D(filters=1, kernel_size=(1, 1), activation=None)(x)\n",
        "    output = Activation('sigmoid')(x)\n",
        "\n",
        "\n",
        "    return Model(inputs=inputs, outputs=output,name=\"decoder\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "40da30a3-6e92-4bf8-b31e-c97fb5903c79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40da30a3-6e92-4bf8-b31e-c97fb5903c79",
        "outputId": "be852423-94e2-4a7e-c2bc-fad287499825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, 16, 16, 256)\n",
            "(None, 32, 32, 512)\n",
            "(None, 64, 64, 256)\n",
            "(None, 128, 128, 64)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "decoder_part = decoder(input_shape=(8,8,512), skip_connections=encoder_part.outputs, num_filters_list=[256,512,256,64,32])\n",
        "# decoder_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1ae854dc-6600-4db6-9d4f-1af1e13427fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1ae854dc-6600-4db6-9d4f-1af1e13427fd",
        "outputId": "fc355800-000e-4259-8657-615e97e7e877"
      },
      "outputs": [],
      "source": [
        "# encoder_part.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "994j-d2tdhyB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "994j-d2tdhyB",
        "outputId": "0ad0d7e5-ec9b-4a0c-8961-9b137e7ac989"
      },
      "outputs": [],
      "source": [
        "# decoder_part.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "j98g5xb5dqQN",
      "metadata": {
        "id": "j98g5xb5dqQN"
      },
      "outputs": [],
      "source": [
        "def DSUNET(encoder, decoder):\n",
        "    inputs = encoder.input\n",
        "    encoded = encoder(inputs)\n",
        "    outputs = decoder(encoded)\n",
        "    autoencoder = Model(inputs, outputs, name=\"DSUNET\")\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q_w0YqmmfVbn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "q_w0YqmmfVbn",
        "outputId": "961329cd-21c5-4ca2-d191-a60224f26c7c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.signal import convolve2d\n",
        "import cv2\n",
        "\n",
        "# Define SRM filters\n",
        "SRM_Kernels = [\n",
        "    (1/4) * np.array([\n",
        "        [0, 0, 0, 0, 0],s\n",
        "        [0, -1, 2, -1, 0],\n",
        "        [0, 2, -4, 2, 0],\n",
        "        [0, -1, 2, -1, 0],\n",
        "        [0, 0, 0, 0, 0]\n",
        "    ]),\n",
        "    (1/12) * np.array([\n",
        "        [-1, 2, -2, 2, -1],\n",
        "        [2, -6, 8, -6, 2],\n",
        "        [-2, 8, -12, 8, -2],\n",
        "        [2, -6, 8, -6, 2],\n",
        "        [-1, 2, -2, 2, -1]\n",
        "    ]),\n",
        "    (1/2) * np.array([\n",
        "        [0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0],\n",
        "        [0, 1, -2, 1, 0],\n",
        "        [0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0]\n",
        "    ])\n",
        "]\n",
        "\n",
        "def apply_srm_filter(image):\n",
        "    # Initialize the output with the same shape as the input\n",
        "    filtered_image = np.zeros((256, 256, 3), dtype=np.float32)\n",
        "\n",
        "    # Apply each filter to each channel\n",
        "    for i, kernel in enumerate(SRM_Kernels):\n",
        "        for channel in range(3):  # Assuming 3 RGB channels\n",
        "            filtered_image[..., i] += convolve2d(image[..., channel], kernel, mode='same', boundary='symm')\n",
        "\n",
        "    return filtered_image\n",
        "\n",
        "# # Load and preprocess a sample 256x256x3 image\n",
        "# image = cv2.imread('/content/Tp_S_NRN_S_N_pla00005_pla00005_10937.jpg')  # Replace with your image path\n",
        "# image = cv2.resize(image, (256, 256))  # Resize to 256x256\n",
        "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# # Apply the SRM filter\n",
        "# filtered_image = apply_srm_filter(image)\n",
        "# print(image.shape)\n",
        "\n",
        "# Display the result (normalize for visualization)\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.imshow((filtered_image - filtered_image.min()) / (filtered_image.max() - filtered_image.min()))\n",
        "# plt.title(\"Filtered Image with SRM\")\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "5GP2dmU8hz2A",
      "metadata": {
        "id": "5GP2dmU8hz2A"
      },
      "outputs": [],
      "source": [
        "def ds_unet(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "050129f1",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf-gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
